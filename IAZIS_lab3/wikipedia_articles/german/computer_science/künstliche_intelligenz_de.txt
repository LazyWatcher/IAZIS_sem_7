Заголовок: Künstliche Intelligenz
URL: https://de.wikipedia.org/wiki/K%C3%BCnstliche_Intelligenz
Язык: de
Категория: computer_science
Дата загрузки: 2025-12-07 12:00:40
Длина текста: 73791 символов

Künstliche Intelligenz (KI), englisch artificial intelligence, daher auch artifizielle Intelligenz (AI), bezeichnet im weitesten Sinne computerbasierte Systeme, die ihre (virtuelle oder reale) Umgebung analysieren können, um daraus relevante Informationen zu abstrahieren, welche sie nutzen, um Entscheidungen zu treffen, die ihre Chance erhöhen, definierte Ziele zu erreichen. Damit unterscheiden sich KI-gestützte Systeme von regelbasierten Systemen ohne Fähigkeit zur eigenständigen Anpassung ihres Verhaltens, die ausschließlich fest vorgegebene Anweisungen ausführen. KI ist außerdem die Bezeichnung für das Teilgebiet der Informatik, das sich mit der Entwicklung und Erforschung von Software und Methoden befasst, die besagte Systeme hervorbringen. Die KI als Forschungsfeld befasst sich in diesem Zusammenhang beispielsweise mit der Automatisierung intelligenten Verhaltens und dem maschinellen Lernen sowie der Formalisierung von Bewusstsein und Kreativität. Der Begriff ist schwierig zu definieren, da es verschiedene Definitionen von Intelligenz gibt. Mit der Zeit haben sich viele Bereiche zu den Methoden der KI entwickelt. Weiterhin wird unterschieden, welche Probleme mit den Methoden der KI beschrieben werden. Dabei entstanden zwei Bereiche: schwache KI und starke KI. Hier lassen sich viele Kategorien bilden und der wissenschaftliche Diskurs ist noch nicht sehr weit in der Zuordnung von Themen zu den Arten der Probleme. Der ingenieurwissenschaftliche Teil der Informatik befasst sich damit, wie solche Systeme realisiert werden können. Beispiele dafür sind Multiagentensysteme, Expertensysteme, Transformer oder serviceorientierte Architekturen. Eigenschaften von Intelligenz Versuchsweise wird Intelligenz definiert als die Eigenschaft, die ein Wesen befähigt, angemessen und vorausschauend in seiner Umgebung zu agieren. Dazu gehören die Fähigkeiten Umgebungsdaten wahrzunehmen, d. h. auf Stimuli zu reagieren Informationen aufzunehmen, zu verarbeiten und als Wissen zu speichern, Sprache zu verstehen und zu erzeugen, Probleme zu lösen und zu handeln Ziele zu definieren, zu erreichen und zu modifizieren Autonom Entscheidungen zu treffen. Praktische Erfolge der KI werden schnell in die Anwendungsbereiche integriert und werden dann von vielen nicht mehr als KI angesehen, auch wenn sie deren Definition erfüllen. Dieses Phänomen wird auch als „AI effect“ bezeichnet. Begriffsherkunft Der Begriff artificial intelligence (künstliche Intelligenz) wurde 1955 geprägt von dem US-amerikanischen Informatiker John McCarthy im Rahmen eines Förderantrags an die Rockefeller-Stiftung für das Dartmouth Summer Research Project on Artificial Intelligence, einem Forschungsprojekt, bei dem sich im Sommer 1956 eine Gruppe von zehn Wissenschaftlern über ca. acht Wochen mit der Thematik befasste. Definitionsversuche Es existieren zahlreiche Definitionen für den Begriff der KI. Je nach Sichtweise wird die künstliche Intelligenz in Industrie, Forschung und Politik entweder über die zu erzielenden Anwendungen oder den Blick auf die wissenschaftlichen Grundlagen definiert: Die Definitionen für künstliche Intelligenz lassen sich nach Stuart J. Russell und Peter Norvig in vier Kategorien einteilen: Nachbildung von menschlichem Denken Nachbildung von rationalem Denken Nachbildung von menschlichem Verhalten Nachbildung von rationalem Verhalten EU-rechtliche Definition Die KI-Verordnung der EU definiert in Artikel 3 (Begriffsbestimmungen) ein „KI-System“ wie folgt: Diese Definition wird im Erwägungsgrund 12 etwas allgemeinverständlicher eingeordnet. Alltagstaugliche Definitionen Um ein System im Alltag konkret als „KI“ oder „nicht KI“ einordnen zu können, ist in vielen Unternehmen eine Annäherung über möglichst konkrete und verständliche Kriterien notwendig. Diese werden z. B. von IT- und Compliance-Stakeholdern erarbeitet, stehen im Kontext vorhandener Informationssicherheits-, Compliance- und/oder Risikomanagement-Systeme und orientieren sich - Stand Dezember 2024 - beispielsweise an folgenden Definitionen: Ein System wird als „KI-System“ eingestuft, wenn es mindestens eine Komponente enthält, deren Ausgaben auf Verarbeitungs- bzw. Entscheidungsmustern beruhen, die es zuvor in einer Lernphase auf Basis großer Datenmengen selbst generiert hat. Ebenfalls als eindeutiges Merkmal gilt, dass die Ausgabe eines KI-Systems zu einer spezifischen Eingabe nicht alleine über Programmierung, Konfiguration und Parametrisierung vorhergesagt werden kann, sondern bestenfalls auf Basis der Daten, mit denen das System angelernt wurde. Hier liegt ein risikobasierter Ansatz zugrunde, da die KI-Komponente als Black Box eingestuft wird, deren innere Funktionsweise nicht transparent ist. (Vgl. Black-Box-Test) Diese Annäherungen können sowohl auf generative als auch auf prädiktive KI angewendet werden. Ein Non-KI-System, in dessen Algorithmen ein zuvor woanders erlerntes KI-Verarbeitungsmuster integriert ist, wird aufgrund der Risiken, die sich aus der o. g. Intransparenz ergeben, derzeit meist ebenfalls als KI-System eingeordnet. Dies betrifft beispielsweise die Mehrfachverwendung eines allgemeinen LLM-Modells in unterschiedlichen fachlichen Kontexten. (Stand Dezember 2024) Der Vorteil der vorgenannten Annäherungen liegt darin, dass sie die Unschärfen des „Intelligenz“-Begriffs sowie Interpretationsspielräume der o. g. EU-Verordnung vermeiden, indem ausschließlich bekannte technische Aspekte der in Frage kommenden Systeme zugrunde gelegt werden: Für jeden Quellcode (White Box) kann eine eindeutige Aussage abgeleitet werden, ob eine Lernfähigkeit (z. B. nach Art der unten aufgeführten Methoden) eingebaut ist oder nicht. Ist der Quellcode nicht einsehbar, kann der Hersteller/Programmierer konsultiert werden. Unterscheidungsbeispiel: Ein Navigationssystem ist ein KI-System, wenn es anhand von Daten zu einer Teilmenge aller möglichen Fahrten „angelernt“ wurde, für jede mögliche Fahrt die schnellste Route zu finden. Ein Navigationssystem ist kein KI-System, wenn es die schnellste Route aufgrund unveränderlicher*, mindestens dem Hersteller/Programmierer bekannter Algorithmen und einer zuvor nach ebenso bekannten Regeln optimierten, unveränderlichen* Datenbank ermittelt. (*unveränderlich mit Ausnahme herkömmlicher Updates, z. B. für Sicherheit, Effizienzverbesserungen, neue Funktionen und Kartenaktualisierungen) Im vorgenannten Beispiel liegt der Fokus auf der Routenfindung. Eine ggf. vorgeschaltete Sprachsteuerung wäre separat zu betrachten. Metaphorik Der Diskurs über KI ist stark von einer metaphorischen Sprache geprägt. Begriffe wie künstliche Intelligenz und maschinelles Lernen sind selbst anthropomorphe Metaphern, die auf die menschliche Kognition anspielen. Eine weitere gängige Metapher ist die Black Box, die die Intransparenz vieler KI-Systeme beschreibt. Im wissenschaftlichen Diskurs werden große Sprachmodelle auch als stochastische Papageien bezeichnet, um darauf hinzuweisen, dass sie Texte erzeugen, ohne den Inhalt wirklich zu verstehen. Der Autor Ted Chiang vergleicht große Sprachmodelle mit einem unscharfen JPEG aus dem Netz, um Kompressionsmechanismen zu veranschaulichen. Anthropomorphe Metaphern sind umstritten, da sie ein übertriebenes oder verzerrtes Bild von KI-Systemen vermitteln können. Alternativ diskutieren Forscher und Journalisten Metaphern wie KI als Werkzeuge, Spiegel, Tiere, Organismen oder Naturphänomene. Die Wahl einer Metapher beeinflusst nicht nur das öffentliche Verständnis von KI, sondern spielt auch eine Rolle in der Gesetzgebung, Regulierung und wissenschaftlichen Forschung. Starke und schwache KI Starke KI wären kognitive Systeme, die auf Augenhöhe mit Menschen die Arbeit zur Erledigung schwieriger Aufgaben übernehmen können. Demgegenüber geht es bei schwacher KI darum, konkrete Anwendungsprobleme zu meistern. Das menschliche Denken und technische Anwendungen sollen hier in Einzelbereichen unterstützt werden. Die Fähigkeit zu lernen ist eine Hauptanforderung an KI-Systeme und muss ein integraler Bestandteil sein, der nicht erst nachträglich hinzugefügt werden darf. Ein zweites Hauptkriterium ist die Fähigkeit eines KI-Systems, mit Unsicherheiten und Wahrscheinlichkeiten (sowie mit probabilistischen Informationen) umzugehen. Insbesondere sind solche Anwendungen von Interesse, zu deren Lösung nach allgemeinem Verständnis eine Form von „Intelligenz“ notwendig zu sein scheint. Letztlich geht es der schwachen KI somit um die Simulation intelligenten Verhaltens mit Mitteln der Mathematik und der Informatik, es geht ihr nicht um Schaffung von Bewusstsein oder um ein tieferes Verständnis von Intelligenz. Während die Frage nach der prinzipiellen Machbarkeit starker KI bis heute offen ist, sind bei der schwachen KI in den letzten Jahren bedeutende Fortschritte erzielt worden. Unterschieden wird nach den Fragestellungen, die untersucht werden, nicht nach den verwendeten Methoden. Schwache KI ist stark in der Anwendung, erlaubt eine Monetarisierung und prägt das gesellschaftliche Verständnis. Beispiele sind die Fehlererkennung in Geweben, die Wettervorhersage, das automatisierte Netzwerkmanagement oder große Sprachmodelle. Starke KI befasst sich mit Grundsatzfragen wie der Beschreibung von Bewusstsein, der Repräsentation und Aktualisierung von Wissen (z. B. dem Umgang mit Widersprüchen) oder der Frage, was erforderlich ist, um Intelligenz nachzuweisen. Die beiden Bereiche lassen sich nicht scharf trennen. Methoden zur Problemanalyse können je nach Interpretation beiden Klassen zugeordnet werden. Mitunter wird die Frage, ob und wie eine Künstliche allgemeine Intelligenz oder eine Superintelligenz erzeugt werden kann, der starken KI zugeordnet. Die philosophische Interpretation dieser Unterteilung umfasst zwei Auffassungen: Schwache KI kann handeln (etwa autonomes Fahren), jedoch ohne Bewusstsein; Vertreter der starken KI hingegen halten ein künstliches Bewusstsein für möglich. Welche Auffassung zutrifft, ist weiterhin ungeklärt. Der ingenieurwissenschaftliche Teil der Informatik befasst sich mit der praktischen Realisierung solcher Systeme. Beispiele sind Multiagentensystem, Expertensystem, Transformer (Maschinelles Lernen) und Serviceorientierte Architektur. Ein starkes KI-System muss nicht viel mit dem Menschen gemeinsam haben. Es wird wahrscheinlich eine andersartige kognitive Architektur aufweisen und auch in seinen Entwicklungsstadien nicht mit den evolutionären kognitiven Stadien des menschlichen Denkens vergleichbar sein (Evolution des Denkens). Vor allem ist nicht anzunehmen, dass eine künstliche Intelligenz Gefühle wie Liebe, Hass, Angst oder Freude besitzt. Forschungsgebiete Neben den Forschungsergebnissen der Kerninformatik selbst sind in die Erforschung der KI Ergebnisse der Psychologie, Neurologie und Neurowissenschaften, der Mathematik und Logik, Kommunikationswissenschaft, Philosophie und Linguistik eingeflossen. Umgekehrt nahm die Erforschung der KI auch ihrerseits Einfluss auf andere Gebiete, vor allem auf die Neurowissenschaften. Dies zeigt sich in der Ausbildung des Bereichs der Neuroinformatik, der der biologieorientierten Informatik zugeordnet ist, sowie der Computational Neuroscience. Bei künstlichen neuronalen Netzen handelt es sich um Techniken, die ab Mitte des 20. Jahrhunderts entwickelt wurden und auf der Neurophysiologie aufbauen. KI stellt somit kein geschlossenes Forschungsgebiet dar. Vielmehr werden Techniken aus verschiedenen Disziplinen verwendet, ohne dass diese eine Verbindung miteinander haben müssen. Wichtige Tagungen sind die International Joint Conference on Artificial Intelligence (IJCAI), die seit 1969 stattfindet und die seit 1982 von der Europäischen Vereinigung für künstliche Intelligenz (EurAI) organisierte European Conference on Artificial Intelligence (ECAI). Seit der Begriffsprägung im Jahre 1955 hat sich eine Reihe relativ selbständiger Teildisziplinen herausgebildet: Mustererkennung, wozu auch Spracherkennung und Handschrifterkennung zählen; Software-Agent Wissensmodellierung einschließlich Logischer Programmierung und Inferenzmaschinen; Expertensysteme, Frage-Antwort-Systeme und Chatbots; Maschinelles Lernen; Künstliche neuronale Netze und Deep Learning; Computer Vision; Robotik; und Universelle Spieleprogramme. Zur Forschungsrichtung künstliches Leben bestehen enge Beziehungen. Das Fernziel der KI ist die als starke KI oder künstliche allgemeine Intelligenz bezeichnete Fähigkeit eines intelligenten Agenten, jede intellektuelle Aufgabe zu verstehen oder zu erlernen, die der Mensch oder ein anderes Lebewesen bewältigen kann. Geschichte Teilgebiete Wissensbasierte Systeme Wissensbasierte Systeme modellieren eine Form rationaler Intelligenz für sogenannte Expertensysteme. Diese sind in der Lage, auf eine Frage des Anwenders auf Grundlage formalisierten Fachwissens und daraus gezogener logischer Schlüsse Antworten zu liefern. Beispielhafte Anwendungen finden sich in der Diagnose von Krankheiten oder der Suche und Beseitigung von Fehlern in technischen Systemen. Beispiele für wissensbasierte Systeme sind Cyc und Watson. Musteranalyse und Mustererkennung Visuelle Intelligenz ermöglicht es, Bilder bzw. Formen zu erkennen und zu analysieren. Als Anwendungsbeispiele seien hier Handschrifterkennung, Identifikation von Personen durch Gesichtserkennung, Abgleich der Fingerabdrücke oder der Iris, industrielle Qualitätskontrolle und Fertigungsautomation (letzteres in Kombination mit Erkenntnissen der Robotik) genannt. Mittels sprachlicher Intelligenz ist es beispielsweise möglich, einen geschriebenen Text in gesprochene Sprache umzuwandeln (Sprachsynthese) und umgekehrt einen gesprochenen Text zu verschriftlichen (Spracherkennung). Diese automatische Sprachverarbeitung kann erweitert werden, so dass etwa durch latente semantische Analyse (kurz LSI) Wörtern und Texten Bedeutung beigemessen werden kann. Beispiele für Systeme zur Mustererkennung sind Google Brain und Microsoft Adam. Mustervorhersage Die Mustervorhersage ist eine Erweiterung der Mustererkennung. Sie stellt die Grundlage des von Jeff Hawkins definierten hierarchischen Temporalspeichers dar. Solche Systeme haben den Vorteil, dass sie z. B. nicht nur ein bestimmtes Objekt in einem Einzelbild erkennen (Mustererkennung), sondern aus einer Serie von Bildern vorhersagen können, wo sich das Objekt als Nächstes befinden wird. Robotik Die Robotik beschäftigt sich mit manipulativer Intelligenz. Mit Hilfe von Robotern können unter anderem gefährliche Tätigkeiten wie etwa die Minensuche oder auch immer gleiche Manipulationen, wie sie beim Schweißen oder Lackieren auftreten können, automatisiert werden. Der Grundgedanke ist es, Systeme zu schaffen, die intelligente Verhaltensweisen von Lebewesen nachvollziehen können. Beispiele für derartige Roboter sind ASIMO und Atlas. Künstliches Leben KI überlappt sich mit der Disziplin künstliches Leben (Artificial life, AL), und wird als übergeordnete oder auch als eine Subdisziplin gesehen. AL muss deren Erkenntnisse integrieren, da Kognition eine Kerneigenschaft von natürlichem Leben ist, nicht nur des Menschen. AI-Alignment Das junge Forschungsfeld des AI-Alignment (zu deutsch KI-Ausrichtung) beschäftigt sich mit der Ausrichtung von KI nach menschlichen Werten und Normen. Unabhängig von der Frage, ob die jeweilige KI über eine Form von Bewusstsein verfügt, verhält sich jede KI entsprechend ihrem Training. Unter anderem durch Fehler oder Lücken im Training kann einer KI leicht Verhalten antrainiert werden, das nicht mit menschlichen Werten vereinbar ist. Die Forschung versucht herauszufinden, wie und ob ethisches Verhalten in KI sichergestellt werden kann, um Probleme wie im Einsatz von KI in Krankenhäusern und Gerichtssälen zu verhindern, aber auch, um die Risiken durch weit fortgeschrittene KI wie im Falle von technologischer Singularität, zu minimieren. Methoden Die Methoden der KI lassen sich grob in zwei Dimensionen einordnen: symbolische vs. neuronale KI und Simulationsmethode vs. phänomenologische Methode. Die Zusammenhänge veranschaulicht die folgende Grafik: Die Neuronale KI verfolgt einen Bottom-up-Ansatz und möchte das menschliche Gehirn möglichst präzise nachbilden. Die symbolische KI verfolgt umgekehrt einen Top-down-Ansatz und nähert sich den Intelligenzleistungen von einer begrifflichen Ebene her. Die Simulationsmethode orientiert sich so nah wie möglich an den tatsächlichen kognitiven Prozessen des Menschen. Dagegen kommt es dem phänomenologischen Ansatz nur auf das Ergebnis an. Viele ältere Methoden, die in der KI entwickelt wurden, basieren auf heuristischen Lösungsverfahren. In jüngerer Zeit spielen mathematisch fundierte Ansätze aus der Statistik, der mathematischen Programmierung und der Approximationstheorie eine bedeutende Rolle. Die konkreten Techniken der KI lassen sich grob in Gruppen einteilen: Suchen Die KI beschäftigt sich häufig mit Problemen, bei denen nach bestimmten Lösungen gesucht wird. Verschiedene Suchalgorithmen werden dabei eingesetzt. Ein Paradebeispiel für die Suche ist der Vorgang der Wegfindung, der in vielen Computerspielen eine zentrale Rolle einnimmt und auf Suchalgorithmen wie dem A*-Algorithmus basiert. Planen Neben dem Suchen von Lösungen stellt das Planen einen wichtigen Aspekt der KI dar. Der Vorgang des Planens unterteilt sich dabei in zwei Phasen: Die Zielformulierung: Ausgehend vom momentanen Umgebungs- bzw. Weltzustand wird ein Ziel definiert. Ein Ziel ist hierbei eine Menge von Weltzuständen, bei der ein bestimmtes Zielprädikat erfüllt ist. Die Problemformulierung: Nachdem bekannt ist, welche Ziele angestrebt werden sollen, wird in der Problemformulierung festgelegt, welche Aktionen und Weltzustände betrachtet werden sollen. Es existieren hierbei verschiedene Problemtypen. Planungssysteme planen und erstellen aus solchen Problembeschreibungen Aktionsfolgen, die Agentensysteme ausführen können, um ihre Ziele zu erreichen. Optimierungsmethoden Oft führen Aufgabenstellungen der KI zu Optimierungsproblemen. Diese werden je nach Struktur entweder mit Suchalgorithmen aus der Informatik oder, zunehmend, mit Mitteln der mathematischen Optimierung gelöst. Bekannte heuristische Suchverfahren aus dem Kontext der KI sind evolutionäre Algorithmen. Logisches Schließen Eine Fragestellung der KI ist die Erstellung von Wissensrepräsentationen, die dann für automatisches logisches Schließen benutzt werden können. Menschliches Wissen wird dabei – soweit möglich – formalisiert, um es in eine maschinenlesbare Form zu bringen. Diesem Ziel haben sich die Entwickler diverser Ontologien verschrieben. Schon früh beschäftigte sich die KI damit, automatische Beweissysteme zu konstruieren, die Mathematikern und Informatikern beim Beweisen von Sätzen und beim Programmieren (Logikprogrammierung) behilflich wären. Zwei Schwierigkeiten zeichneten sich ab: Formuliert man Sätze in den natürlicher Sprache nahen, relativ bequemen Beschreibungssprachen, werden die entstehenden Suchprobleme allzu aufwändig. In der Praxis mussten Kompromisse geschlossen werden, bei denen die Beschreibungssprache für den Benutzer etwas umständlicher, die zugehörigen Optimierungsprobleme für den Rechner dafür jedoch einfacher zu handhaben waren (Prolog, Expertensysteme). Selbst mächtige Beschreibungssprachen werden unhandlich, wenn man versucht, unsicheres oder unvollständiges Wissen zu formulieren. Für praktische Probleme kann dies eine ernste Einschränkung sein. Die aktuelle Forschung untersucht daher Systeme, die die Regeln der Wahrscheinlichkeitsrechnung anwenden, um Unwissen und Unsicherheit explizit zu modellieren. Algorithmisch unterscheiden sich diese Methoden von den älteren Verfahren: neben Symbolen werden auch Wahrscheinlichkeitsverteilungen manipuliert. Eine andere Form des logischen Schließens stellt die Induktion dar (Induktionsschluss, Induktionslogik), in der Beispiele zu Regeln verallgemeinert werden (maschinelles Lernen). Auch hier spielen Art und Mächtigkeit der Wissensrepräsentation eine wichtige Rolle. Man unterscheidet zwischen symbolischen Systemen, in denen das Wissen – sowohl die Beispiele als auch die induzierten Regeln – explizit repräsentiert ist, und subsymbolischen Systemen wie neuronalen Netzen, denen zwar ein berechenbares Verhalten „antrainiert“ wird, die jedoch keinen Einblick in die erlernten Lösungswege erlauben. Approximationsmethoden In vielen Anwendungen geht es darum, aus einer Menge von Daten eine allgemeine Regel abzuleiten (maschinelles Lernen). Mathematisch führt dies zu einem Approximationsproblem. Im Kontext der KI wurden hierzu unter anderem künstliche neuronale Netze vorgeschlagen, die als universale Funktionsapproximatoren eingesetzt werden können, jedoch insbesondere bei vielen verdeckten Schichten schwer zu analysieren sind. Manchmal verwendet man deshalb alternative Verfahren, die mathematisch einfacher zu analysieren sind. Künstliches neuronales Netz Große Fortschritte erzielt die künstliche Intelligenz in jüngerer Zeit im Bereich künstlicher neuronaler Netze, auch unter dem Begriff Deep Learning bekannt. Dabei werden neuronale Netze, die grob von der Struktur des Gehirns inspiriert sind, künstlich auf dem Computer simuliert. Viele der jüngeren Erfolge wie bei Handschrifterkennung, Spracherkennung, Gesichtserkennung, autonomem Fahren, maschineller Übersetzung wie DeepL, AlphaGo, ChatGPT, DeepSeek beruhen auf dieser Technik. Anwendungen Künstliche Intelligenz hat das Potenzial für eine Vielzahl von Verwendungen in Forschung, Wirtschaft und im Konsumbereich. Sie stellt zudem die zentrale Technologie der Industrie 5.0 dar. Noch im Jahr 2025 gab es Stimmen, die der Auffassung waren, dass Künstliche Intelligenz trotz ihres Nutzens in einzelnen Anwendungsbereichen der Gesellschaft insgesamt bislang keinen erkennbaren Beitrag zur Produktivitätssteigerung geleistet habe. Absehbar und teils realisiert waren zu diesem Zeitpunkt Nutzungen in den Bereichen Mobilität und Logistik, der Landwirtschaft, Gesundheit und zur Optimierung der Energieeffizienz. Turing-Test Um ein Kriterium zu haben, wann eine Maschine eine dem Menschen gleichwertige Intelligenz simuliert, wurde von Alan Turing der nach ihm benannte Turing-Test vorgeschlagen: Dazu stellt ein Mensch per Terminal (Bildschirm und Tastatur, oder auch Lautsprecher und Mikrofon) beliebige Fragen, ohne dabei zu wissen, ob diese von einem anderen Menschen oder einer Maschine beantwortet werden. Der Fragesteller muss danach entscheiden, ob es sich beim Interviewpartner um eine Maschine oder einen Menschen handelte. Ist die Maschine nicht von einem Menschen zu unterscheiden, so ist sie laut Turing intelligent. Bisher konnte keine Maschine den Turing-Test zweifelsfrei bestehen. Seit 1991 existiert der Loebner-Preis für den Turing-Test. Technologische Singularität Grob wird unter der technologischen Singularität der hypothetische Zeitpunkt verstanden, an dem künstliche Intelligenz die menschliche Intelligenz übertrifft. Ab diesem Zeitpunkt wird die weitere technologische Entwicklung hauptsächlich von KI vorangetrieben und nicht mehr vom Menschen. Bewusstsein bei künstlicher Intelligenz In den Neurowissenschaften ist es eine Grundannahme, dass Bewusstseinsprozesse mit neuronalen Prozessen des Gehirns korrelieren (siehe Neuronales Korrelat des Bewusstseins). Nach Jürgen Schmidhuber ist Bewusstsein nur ein Nebenprodukt des Problemlösens des Gehirns. So sei auch bei künstlichen Problemlösern (z. B. autonomen mobilen Robotern) von Vorteil, wenn diese sich ihrer selbst und ihrer Umgebung „bewusst“ seien. Schmidhuber bezieht sich bei „Bewusstsein“ im Kontext autonomer Roboter auf ein digitales Weltmodell inklusive des Systems selbst, nicht jedoch auf subjektive Erlebnisqualitäten von Zuständen. Ein Weltmodell könnte im Kontext von Reinforcement Learning dadurch erlernt werden, dass Aktionen belohnt werden, die das Weltmodell erweitern. Solche Überlegungen sind jedoch hoch spekulativ, da weder eine allgemein akzeptierte Definition, geschweige denn eine anerkannte Theorie von Bewusstsein existiert. Wenn Bewusstsein eine emergente Eigenschaft des Informationsverarbeitens ist, wäre es möglich, dass KI Bewusstsein erlangt. Da die meisten Definitionen jedoch ein „inneres Erleben“ der Wahrnehmung mit Bewusstsein verbinden, das beim Menschen zu komplexen Weltanschauungen führt, gibt es bislang keine empirischen Belege dafür, dass KI-Systeme über etwas Ähnliches verfügen. Ihre „Intelligenz“ ist rein funktional und instrumental. Im Gegensatz zum menschlichen Gehirn basieren aktuelle KI-Systeme auf Algorithmen, neuronalen Netzen und statistischen Modellen. Sie verarbeiten Daten nach mathematischen Regeln ohne echte Kreativität oder Phantasie. Andererseits lassen sich innere Zustände nicht beweisen, sodass es keine verlässliche Antwort geben kann. Angrenzende Wissenschaften Sprachwissenschaft Die Interpretation menschlicher Sprache durch Maschinen besitzt bei der KI-Forschung eine entscheidende Rolle. So ergeben sich etwaige Ergebnisse des Turing-Tests vor allem in Dialogsituationen, die bewältigt werden müssen. Die Sprachwissenschaft liefert mit ihren Grammatikmodellen und psycholinguistischen Semantikmodellen wie der Merkmals- oder der Prototypensemantik Grundlagen für das maschinelle „Verstehen“ komplexer natürlichsprachlicher Phrasen. Zentral ist die Frage, wie Sprachzeichen eine tatsächliche Bedeutung für eine künstliche Intelligenz haben können. Das Chinese-Room-Argument des Philosophen John Searle sollte indes zeigen, dass es selbst dann möglich wäre, den Turing-Test zu bestehen, wenn den verwendeten Sprachzeichen dabei keinerlei Bedeutung beigemessen wird. Insbesondere Ergebnisse aus dem Bereich Embodiment betonen zudem die Relevanz von solchen Erfahrungen, die auf der Verkörperung eines Agenten beruhen sowie dessen Einbindung in eine sinnvolle Umgebung für jede Form von Kognition, also auch zur Konstruktion von Bedeutung durch eine Intelligenz. Eine Schnittstelle zwischen der Linguistik und der Informatik bildet die Computerlinguistik, die sich unter anderem mit maschineller Sprachverarbeitung und künstlicher Intelligenz beschäftigt. Psychologie Die Psychologie beschäftigt sich unter anderem mit dem Begriff Intelligenz. Psychotherapie In der Psychotherapieforschung existieren seit geraumer Zeit experimentelle Anwendungen der künstlichen Intelligenz, um Defizite und Engpässe in der psychotherapeutischen Versorgung zu überbrücken und Kosten zu sparen. Philosophie Die philosophischen Aspekte der KI-Problematik gehören zu den weitreichendsten der gesamten Informatik. Die Antworten, die auf die zentralen Fragen dieses Bereiches gegeben werden, reichen weit in ontologische und erkenntnistheoretische Themen hinein, die das Denken des Menschen schon seit den Anfängen der Philosophie beschäftigen. Wer solche Antworten gibt, muss die Konsequenzen daraus auch für den Menschen und sich selbst ziehen. Nicht selten möchte man umgekehrt vorgehen und die Antworten, die man vor der Entwicklung künstlicher Intelligenz gefunden hat, auf diese übertragen. Doch wie sich zeigte, hat die künstliche Intelligenz zahlreiche Forscher dazu veranlasst, Probleme wie das Verhältnis zwischen Materie und Geist, die Ursprünge des Bewusstseins, die Grenzen der Erkenntnis, das Problem der Emergenz, die Möglichkeit außermenschlicher Intelligenz usw. in einem neuen Licht zu betrachten und zum Teil neu zu bewerten. Eine dem metaphysischen bzw. auch idealistischen Denken verpflichtete Sichtweise hält es (im Sinn einer schwachen KI) für unmöglich, dass Maschinen jemals mehr als nur simuliertes Bewusstsein mit wirklicher Erkenntnis und Freiheit besitzen könnten. Aus ontologischer Sicht kritisiert der amerikanische Philosoph Hubert Dreyfus die Auffassung der starken KI. Aufbauend auf der von Martin Heidegger in dessen Werk Sein und Zeit entwickelten Ontologie der „Weltlichkeit der Welt“ versucht Dreyfus zu zeigen, dass hinter das Phänomen der Welt als sinnhafte Bedeutungsganzheit nicht zurückgegangen werden kann: Sinn, d. h. Beziehungen der Dinge in der Welt aufeinander, sei ein Emergenzphänomen, denn es gibt nicht „etwas Sinn“ und dann „mehr Sinn“. Damit erweist sich jedoch auch die Aufgabe, die sinnhaften Beziehungen zwischen den Dingen der Welt in einen Computer einzuprogrammieren, als eigentlich unmögliches bzw. unendliches Vorhaben. Dies deshalb, weil Sinn nicht durch Addition von zunächst sinnlosen Elementen hergestellt werden kann. Eine evolutionär-progressive Denkrichtung sieht es hingegen (im Sinn einer starken KI) als möglich an, dass Systeme der künstlichen Intelligenz einmal den Menschen in dem übertreffen könnten, was derzeit noch als spezifisch menschlich gilt. Dies birgt zum einen die Gefahr, dass solche KI-Maschinen sich gegen die Interessen der Menschen wenden könnten. Andererseits birgt diese Technologie die Chance, Probleme zu lösen, deren Lösung dem Menschen wegen seiner limitierten Kapazitäten schwerfällt (siehe auch technologische Singularität). Weitere Anknüpfungspunkte lassen sich in der analytischen Philosophie finden. Die Ethik der künstlichen Intelligenz erforscht ethische Normen für Entwurf, Herstellung, Testung, Zertifizierung und den Einsatz künstlich intelligenter Systeme und fragt nach Prinzipien für das ethische Verhalten von KI-Systemen. Intensiv untersuchte Themen sind dabei ethische Fragen des autonomen Fahrens und autonomer Waffensysteme sowie die Probleme und Realisierungsmöglichkeiten künstlicher moralischer Agenten. Rechtsphilosophie und Roboterethik gehen der Frage nach, ob eine KI für ihr gesetzwidriges Handeln oder Fehlverhalten verantwortlich gemacht werden kann (z. B. bei einem Autounfall durch ein autonomes Fahrzeug) und wer dafür haftet. Der russisch-amerikanische Biochemiker und Sachbuchautor Isaac Asimov beschreibt in seinen drei Robotergesetzen die Voraussetzungen für ein friedliches und unterstützendes Zusammenleben zwischen KI und Mensch. Diese Gesetze wurden später von anderen Autoren erweitert. Bei Karl Marx finden sich im sogenannten Maschinenfragment, einem Teil der Grundrisse (1857–58), Überlegungen zur Ersetzung menschlicher Arbeitskraft durch Maschinen, die sich auch auf Maschinen mit künstlicher Intelligenz anwenden lassen. Menschenrechte Zu den zentralen Fragen beim KI-Einsatz gehören die Aufteilung rechtlicher Verpflichtungen zwischen Staaten und Unternehmen sowie die Implikationen der Menschenrechte im Hinblick auf den Einsatz von KI in bestimmten Anwendungsbereichen, z. B. bei der Gesichtserkennung oder Erleichterung der Entscheidungsfindung von Gerichten. Auch wird das Ausmaß der technologischen Zusammenarbeit im Bereich der KI mit Staaten, die sich nicht an menschenrechtliche Grundstandards halten, aus wirtschaftsethischer und völkerrechtlicher Perspektive diskutiert. Klimatologie und Ökologie KI kann dazu genutzt werden, mehr Nachhaltigkeit zu erreichen. Eine vom Fraunhofer-Institut für Produktionstechnik und Automatisierung und dem Fraunhofer-Institut für Arbeitswirtschaft und Organisation in Auftrag gegebene Studie sieht hierbei große Potenziale für produzierende Unternehmen. Der Einsatz von KI könne zu effizienteren Produktionsprozessen führen und Ressourcen schonen. Das Unternehmen Bosch gab 2023 an, durch den Einsatz von generativer KI in einem türkischen Werk den Wasserverbrauch, den Ausschuss sowie den Energiebedarf verringert zu haben. Gleichzeitig sei die Anlageneffektivität um ca. zehn Prozent angestiegen. In der Forschung wird allerdings angemahnt, nicht nur auf Nachhaltigkeit durch KI, sondern auch von KI zu achten. So lässt sich etwa ein massiv ansteigender Energieverbrauch durch KI und ein damit verbundener erhöhter Ausstoß des Treibhausgases Kohlenstoffdioxid beobachten. Die Supercomputer, die die Nutzung von KI ermöglichen, haben einen überaus hohen Strombedarf. So verbraucht eine ChatGPT-Anfrage zehn- bis zwanzigmal so viel elektrische Energie wie eine herkömmliche Google-Suche. Die Internationale Energieagentur (IEA) schätzte im Januar 2024, dass sich der weltweite Stromverbrauch durch Rechenzentren, die diese Supercomputer beherbergen, bis 2026 im Vergleich zu 2022 verdoppeln könnte. Der zusätzliche Stromverbrauch würde dabei dem von ganz Japan entsprechen. Der enorme Stromverbrauch von KI ist somit für einen Anstieg der Nutzung fossiler Brennstoffe mitverantwortlich und könnte weltweit die Schließung veralteter Kohlekraftwerke verzögern. Der prognostizierte Stromverbrauch ist so immens, dass die Sorge besteht, dass er die Maßnahmen gegen den menschengemachten Klimawandel negativ beeinflussen könnte. Darüber hinaus benötigen Supercomputer große Mengen an Kühlwasser. Allein das Training von GPT-3 soll schätzungsweise 5,4 Millionen Liter Trinkwasser verbraucht haben. Für 10–50 mittellange Antworten auf Anfragen von Nutzenden benötigt ChatGPT außerdem etwa das Äquivalent von einer Flasche Wasser. Genaue Zahlen zum Energie- und Wasserverbrauch durch KI fehlen aber zumeist, da Unternehmen nicht verpflichtet sind, diese offenzulegen. Eine Studie, die sich mit dem Nutzen von KI für die Ziele für nachhaltige Entwicklung beschäftigte, kommt zu dem Schluss, dass bei 79 % von diesen die Nutzung von KI einen positiven Effekt haben könnte. Gleichzeitig könnten auch bei 35 % der Ziele negative Auswirkungen aus dem Einsatz von KI resultieren. Der Informatiker Rainer Rehak warnte in einem Interview mit der taz allerdings davor, Klimaziele allein durch die Nutzung von KI erreichen zu wollen. Maßnahmen, die mit einer grundsätzlichen Neuorientierung z. B. bei der Stadtentwicklung einhergehen, könnten gegebenenfalls deutlich besser zur Verhinderung von Treibhausgasemissionen beitragen. Siehe auch: Green IT Informatik Die künstliche Intelligenz ist mit den anderen Disziplinen der Informatik eng verzahnt. Eine Abgrenzung kann anhand der erzielten Ergebnisse versucht werden. Hierzu scheint es sinnvoll, verschiedene Dimensionen von Intelligenz zu unterscheiden: Die Fähigkeit zur Verarbeitung beliebiger Symbole (nicht nur Zahlen). Der Aufbau eines inneren Modells der äußeren Welt, eines Selbstmodells, sowie der Beziehung von Selbst und Welt. Die Fähigkeit zu einer zweckentsprechenden Anwendung des Wissens. Die Fähigkeit, die im gespeicherten Wissen enthaltenen Zusammenhänge aufzudecken, d. h. logisch schlussfolgern zu können. Die Fähigkeit zur Verallgemeinerung (Abstraktion) und zur Spezialisierung (d. h. zu Anwendung allgemeiner Zusammenhänge auf konkrete Sachverhalte). Das Vermögen, erworbenes Wissen und vorhandene Erfahrung auf neue, bisher unbekannte Situationen zu übertragen. Die Fähigkeit, sich planvoll zu verhalten und entsprechende Strategien zum Erreichen der Ziele bilden zu können. Anpassungsfähigkeit an verschiedene, sich u. U. zeitlich ändernde Situationen und Problemumgebungen. Lernfähigkeit, verbunden mit dem Vermögen, partiellen Fortschritt oder Rückschritt einschätzen zu können. Die Fähigkeit, auch in unscharf bzw. unvollständig beschriebenen oder erkannten Situationen handeln zu können. Die Fähigkeit zur Mustererkennung (Besitz von Sensoren) und zur aktiven Auseinandersetzung mit der Umwelt (Besitz von Effektoren). Über ein Kommunikationsmittel von der Komplexität und Ausdrucksfähigkeit der menschlichen Sprache verfügen. Seit 1966 wird mit dem Turing Award ein Informatikpreis vergeben. Viele der Preisträger wurden wegen ihrer Errungenschaften im Bereich der Erforschung und Entwicklung künstlicher Intelligenz ausgezeichnet. Kritik an der KI-Forschung Stephen Hawking warnte 2014 vor der KI und sah darin eine Bedrohung für die Menschheit. Durch die KI könnte das Ende der Menschheit eingeleitet werden. Ob die Maschinen irgendwann die Kontrolle übernehmen werden, werde die Zukunft zeigen. Aber es sei klar, dass die Maschinen die Menschen zunehmend vom Arbeitsmarkt verdrängen. Im August 2017 forderten 116 Unternehmer und Experten aus der Technologiebranche (u. a. Mustafa Suleyman, Elon Musk, Yoshua Bengio, Stuart Russell, Jürgen Schmidhuber) in einem offenen Brief an die UN, dass autonome Waffen verboten werden sollten bzw. auf die seit 1983 bestehende CCW-Liste gesetzt werden sollen. Die Certain Conventional Weapons sind von der UN verboten und beinhalten unter anderem Chemiewaffen. Nach Schwarzpulver und der Atombombe drohe die dritte Revolution der Kriegsführung. Zitat aus dem Schreiben: „Wenn diese Büchse der Pandora einmal geöffnet ist, wird es schwierig, sie wieder zu schließen“ und „Einmal erfunden, könnten sie bewaffnete Konflikte erlauben in einem nie dagewesenen Ausmaß, und schneller, als Menschen sie begreifen können“. Terroristen und Despoten könnten die autonomen Waffen nutzen und sogar hacken. Argumentativ entgegengetreten sind solchen Positionen u. a. Rodney Brooks und Jean-Gabriel Ganascia. Jörg Phil Friedrich vertritt den Standpunkt, es sei weniger eine künstliche Intelligenz, die uns in den KI-Systemen begegne, „sondern eine über weite Strecken degenerierte menschliche Intelligenz“. Im Februar 2018 wurde ein Bericht einer Projektgruppe führender Experten im Bereich KI veröffentlicht, der vor möglichen „Bösartige[n] Nutzungen künstlicher Intelligenz“ (englischer Originaltitel: „The Malicious Use of Artificial Intelligence“) warnt. Beteiligt waren daran unter anderem Forscher der Universitäten von Oxford, Yale und Stanford, sowie Entwickler von Microsoft und Google. Der Bericht nimmt Bezug auf schon existierende Technologien und demonstriert anhand von diversen Szenarien, wie diese von Terroristen, Kriminellen und despotischen Regierungen missbraucht werden könnten. Die Autoren des Berichts fordern daher eine engere Zusammenarbeit von Forschern, Entwicklern und Gesetzgeber im Bereich KI und schlagen konkrete Maßnahmen vor, wie die Gefahren des Missbrauchs verringert werden könnten. Der Historiker Yuval Noah Harari sagt, „künstliche Intelligenz und Biotechnologie können zerstören, was den Menschen ausmacht.“ Er warnt vor einem Wettrüsten im Bereich der künstlichen Intelligenz und empfiehlt globale Zusammenarbeit angesichts dieser „existenziellen Bedrohung.“ 2024 äußerte er sich im Wochenmagazin Stern besorgt, weil KI „die erste Technologie“ sei, „die eigene Entscheidungen treffen“ könne. Noch komme sie „recht primitiv daher“, doch schreite die Entwicklung zu schnell voran, ohne dass gegenwärtig die damit verbundenen Risiken eingeschätzt werden könnten. Es sei zu befürchten, die KI könnte eines Tages „Waffensysteme selbständig kontrollieren“ und „allein entscheiden, welche Person sie töten“. Die Risiken für die Demokratie bringt Harari mit der potentiellen Fähigkeit der KI in Verbindung, „das erste totale Überwachungssystem der Geschichte zu errichten“. Richard David Precht wendet sich gegen die Vorstellung, dass künftig böser Wille oder Machtstreben seitens einer entwickelten künstlichen Intelligenz drohe; das Gefahrenpotential liege vielmehr in ihrem falschen Einsatz. Die ehemalige Google-Teamleiterin Timnit Gebru warnt vor dem bias und dem Energiebedarf großer Sprachmodelle, was Diskriminierung und Klimakrise verschärfen könnte. Um solchen ungewollten Effekten vorzubeugen, versucht der Forschungsbereich des AI-Alignments (zu deutsch KI-Ausrichtung) sicherzustellen, dass KI nach menschlichen Werten wie etwa Egalitarismus handelt. (Siehe auch: Green IT) Caroline Criado Perez zeigt in ihrer ausführlichen Recherchearbeit das bestehende Gender-Data-Gaps einen negativen Einfluss auf Trainingsdaten von KI nehmen und so bestehende Diskriminierungen reproduziert werden. Als feministische Kritik im Bezug auf Daten und Technologisierung entwickelten sich bereits in den Anfängen des Internets feministische Praxen wie Cyberfeminismus oder Technofeminismus und prägen den Diskurs der feministischen KI. Vorschläge zum Umgang mit KI Der Präsident von Microsoft, Brad Smith, schlug vor, einen Verhaltenskodex aufzustellen, wie etwa eine Digitale Genfer Konvention, um Risiken der künstlichen Intelligenz zu verringern. Der Ethiker Peter Dabrock empfiehlt im Kontext der Benutzung und Programmierung von künstlicher Intelligenz nicht nur die digitale Kompetenz der Beteiligten zu erhöhen, sondern auch auf klassische Bildungselemente zu setzen. Um mit den dazugehörigen Herausforderungen zurechtzukommen sowie die Fähigkeiten zur Unterscheidung und zur Erkennung von Mehrdeutigkeit zu erhöhen, seien Kenntnisse aus Religion, Literatur, Mathematik, Fremdsprachen, Musik und Sport eine gute Voraussetzung. Der Deutsche Bundestag hat am 28. Juni 2018 eine Enquete-Kommission Künstliche Intelligenz – Gesellschaftliche Verantwortung und wirtschaftliche Potenziale eingesetzt. Am 28. Oktober 2020 hat die Kommission ihren Abschlussbericht vorgelegt. Künstliche Intelligenz ist demnach die nächste Stufe der Digitalisierung. Unter dem Leitbild einer „menschenzentrierten KI“ wird eine „demokratische Gestaltung“ der Entwicklung gefordert, so dass KI-Anwendungen vorrangig auf das Wohl und die Würde der Menschen ausgerichtet seien und einen gesellschaftlichen Nutzen bringen. Um einer Diskriminierung von Menschen entgegenzuwirken „braucht es, wenn KI über Menschen urteilt, einen Anspruch auf Transparenz, Nachvollziehbarkeit und Erklärbarkeit von KI-Entscheidungen, damit eine gerichtliche Überprüfung automatisierter Entscheidungen möglich ist“. 2021 veröffentlichte die EU-Kommission einen Vorschlag über eine KI-Verordnung, die am 12. Juni 2024 mit dem Titel „Verordnung (EU) 2024/1689 des Europäischen Parlaments und des Rates vom 13. Juni 2024 zur Festlegung harmonisierter Vorschriften für künstliche Intelligenz und zur Änderung der Verordnungen (EG) Nr. 300/2008, (EU) Nr. 167/2013, (EU) Nr. 168/2013, (EU) 2018/858, (EU) 2018/1139 und (EU) 2019/2144 sowie der Richtlinien 2014/90/EU, (EU) 2016/797 und (EU) 2020/1828 (Verordnung über künstliche Intelligenz)“ veröffentlicht wurde. Im März 2023 wurde ein u. a. von Elon Musk unterstützter Aufruf zu einer 6-monatigen KI-Entwicklungspause veröffentlicht. Der KI-Investor Fabian Westerheide verwies im Zusammenhang mit seinem 2024 erschienenen Buch Die KI-Nation auf hohe Investitionen einiger Staaten – insbesondere Chinas – in eine eigene KI-Strategie, warnte vor der Gefahr einer Überwachung durch Backdoors beim Einsatz ausländischer KI und betonte die Bedeutung deutscher und gesamteuropäischer Pläne zur KI. Verbreitung von KI in Deutschland Die Zahl der Betriebe, die KI-Technologien einsetzen, ist in Deutschland noch relativ gering. Ende 2018 haben nur sechs Prozent der Unternehmen KI genutzt oder implementiert. 17 Prozent haben angegeben, KI-Einsätze zu testen oder zumindest solche zu planen. Auch die ZEW-Studie kommt zu einem ähnlichen Ergebnis. Im Jahr 2019 haben rund 17.500 Unternehmen im Berichtskreis der Innovationserhebung (produzierendes Gewerbe und überwiegend unternehmensorientierte Dienstleistungen) KI in Produkten, Dienstleistungen oder internen Prozessen eingesetzt. Das sind 5,8 Prozent der Unternehmen im Berichtskreis. Das KI-Observatorium Mit dem Observatorium Künstliche Intelligenz in Arbeit und Gesellschaft (kurz: KI-Observatorium), einem Projekt der Denkfabrik Digitale Arbeitsgesellschaft, fokussiert das Bundesministerium für Arbeit und Soziales die Frage nach den Auswirkungen von KI auf Arbeit und Gesellschaft. Das KI-Observatorium agiert an der Schnittstelle zwischen Politik, Wissenschaft, Wirtschaft und Gesellschaft; es fungiert als Wissensträger und Impulsgeber. Das KI-Observatorium hat die Aufgabe, Effekte von KI in der Arbeitswelt frühzeitig zu antizipieren und Handlungsbedarfe aufzuzeigen. Auf diese Weise leistet die im März 2020 gestartete Arbeitseinheit einen Beitrag zur Realisierung der in der KI-Strategie der Bundesregierung formulierten Ziele – etwa zum sicheren und gemeinwohlorientierten Einsatz von KI. Darüber hinaus soll das KI-Observatorium mithilfe von Dialog- und Beteiligungsformaten unterschiedliche gesellschaftliche Akteure im Umgang mit künstlicher Intelligenz befähigen und bestärken. Die konkreten Aufgabenschwerpunkte des Observatoriums sind in den fünf Handlungsfeldern festgehalten: Technologie-Foresight und Technikfolgenabschätzung KI in der Arbeits- und Sozialverwaltung Ordnungsrahmen für KI/soziale Technikgestaltung Aufbau internationaler und europäischer Strukturen Gesellschaftlicher Dialog und Vernetzung Grundlegende Schwachstellen der KI Zu den auch Ende des Jahres 2024 deutlich feststellbaren grundlegenden Schwachstellen der KI gehören u. a.: Generative KI beinhaltet systemimmanente Probleme, die zum so genannten Halluzinieren führen können, bei dem schlüssige Antworten verfasst werden, die angeblich wahr sind, obwohl es sich tatsächlich um frei erfundene Inhalte handelt. Wenige marktbeherrschende Unternehmen im Zusammenhang mit den weltweiten Internetgiganten kontrollieren durch Ausnutzung ihrer bestehenden Dominanz und durch gezieltes Aufkaufen von KI-Startups die Entwicklung der künstlichen Intelligenz und verstärken dadurch umso mehr ihre monopolartigen Marktstellungen mit all den damit zusammenhängenden Nachteilen. Manipulierbarkeit der Anwendung schon allein durch Auswahl der verwendeten KI-„Trainingsdaten“. Zum Teil gravierende Sicherheitsbedenken: Nutzer von insbesondere generativen KI-Modellen haben kaum Möglichkeiten, Sicherheitslücken zu erkennen. Beispielsweise ist mit Stand Februar 2025 bei der DeepSeek-AI von einer sehr weitreichenden Speicherung von auch vertraulichen Nutzerdaten auszugehen. KI neigt dazu, bereits bestehende gesellschaftliche Diskriminierungsverhältnisse zu reproduzieren. Wenn die Daten, mit denen eine KI trainiert wird, z. B. bereits einen sexistischen oder rassistischen Bias haben, wirkt sich dieser auch auf die Funktionen der KI aus. Es gibt vor allem bei mittels KI automatisierten Entscheidungsprozessen eine Reihe von Beispielen, bei denen marginalisierte Gruppen benachteiligt werden. So wurde z. B. im November 2025 bekannt, dass KI, die Dialekte hört bzw. liest, oft unfair urteilt, indem sie Vorurteile gegenüber Menschen mit Dialekt zum Ausdruck bringt und Eigenschaften wie „ungebildet“ und „unfreundlich“ auswählt. Regulierung und Gesetzgebung Europäische Union Die Verordnung über künstliche Intelligenz (informell meist KI-Verordnung, englisch AI Act) ist eine EU-Verordnung für die Regulierung von künstlicher Intelligenz. Es ist die weltweit erste umfassende Regulierung dieser Art. Das Gesetz regelt den Einsatz von KI unter anderem für die kritische Infrastruktur, Sicherheitsbehörden und Personalverwaltung. Die Europäische Kommission hat das Gesetz am 21. April 2021 vorgeschlagen und einen ersten Entwurf veröffentlicht. Am 28. September 2022 hat die Europäische Kommission in dem Zusammenhang auch den Entwurf einer Richtlinie über Produkthaftung und einer Richtlinie über KI-Haftung veröffentlicht. Haftungsfragen waren zuvor aus der Verordnung herausgenommen worden. In dem Kontext steht auch die Überarbeitung der Maschinenrichtlinie zur EU-Maschinenverordnung, die am 14. Juni 2023 in Kraft getreten ist. Am 9. Dezember 2023 einigten sich die EU-Gesetzgebungsinstitutionen auf die Grundzüge des Gesetzes. Am 12. Juni 2024 hat die EU die KI-Verordnung mit dem Titel „Verordnung (EU) 2024/1689 des Europäischen Parlaments und des Rates vom 13. Juni 2024 zur Festlegung harmonisierter Vorschriften für künstliche Intelligenz und zur Änderung der Verordnungen (EG) Nr. 300/2008, (EU) Nr. 167/2013, (EU) Nr. 168/2013, (EU) 2018/858, (EU) 2018/1139 und (EU) 2019/2144 sowie der Richtlinien 2014/90/EU, (EU) 2016/797 und (EU) 2020/1828 (Verordnung über künstliche Intelligenz)“ veröffentlicht. Hier sind Vorschriften zum Inverkehrbringen, Inbetriebnahme und die Verwendung von KI-Systemen festgelegt. Verbotene Praktiken sind in Kapitel II benannt. Ebenso sind die Kriterien zur Einstufung von KI-Systemen als Hochrisiko-KI-Systeme in Kapitel III beschrieben. Für Hochrisiko-KI-Systeme wird die EU eine Datenbank errichten. Sanktionen gegen die Missachtung der Richtlinie sind mit Geldbußen von 35 Millionen Euro oder sieben Prozent des gesamten weltweiten Umsatzes des verstoßenden Unternehmens belegt. Wie jede EU-Richtlinie muss sie in nationale Gesetze übernommen werden. Für KI-Systeme ist eine EU-Konformitätserklärung vorgeschrieben. Da die KI-Systeme viele Bereiche tangieren, wie am Titel der Verordnung ersichtlich, wurden folgende Richtlinien geändert: Richtlinie 2014/90/EU über Schiffsausrüstung, Richtlinie (EU) 2016/797 über die Interoperabilität des Eisenbahnsystems in der Europäischen Union. Folgende Verordnungen wurden mit der KI-RL auch geändert: Verordnung (EG) Nr. 300/2008 über gemeinsame Vorschriften für die Sicherheit in der Zivilluftfahrt, Verordnung (EU) Nr. 167/2013 über die Genehmigung und Marktüberwachung von land- und forstwirtschaftlichen Fahrzeugen, Verordnung (EU) Nr. 168/2013 über die Genehmigung und Marktüberwachung von zwei- oder dreirädrigen und vierrädrigen Fahrzeugen, Verordnung (EU) 2018/858 über die Genehmigung und die Marktüberwachung von Kraftfahrzeugen und Kraftfahrzeuganhängern sowie von Systemen, Bauteilen und selbstständigen technischen Einheiten für diese Fahrzeuge, Verordnung (EU) 2018/1139 zur Festlegung gemeinsamer Vorschriften für die Zivilluftfahrt und zur Errichtung einer Agentur der Europäischen Union für Flugsicherheit, Verordnung (EU) 2019/2144 über die Typgenehmigung von Kraftfahrzeugen und Kraftfahrzeuganhängern. Basierend auf den Verordnungen der EU haben einige nationale Stellen bereits eigenen Regularien zum Einsatz im öffentlich-rechtlichen Umfeld ausgearbeitet. Vereinigte Staaten In den Vereinigten Staaten gibt es bislang keine Bundesgesetzgebung, die die Verwendung von künstlicher Intelligenz explizit und umfassend reguliert. Dass der Einsatz von KI möglichst global reguliert wird, halten viele US-amerikanische Juristen jedoch für notwendig, so zum Beispiel Anwalt Shabbi S. Khan: „Generative KI hat das Potenzial, katastrophal zu sein“. Auch die US-Regierung hat erkannt, dass die Machtfülle der großen Tech-Unternehmen zu einer Bedrohung der Demokratie werden kann. Im Juli 2023 wollte US-Präsident Joe Biden eine freiwillige Selbstverpflichtung führender KI-Unternehmen einholen, um zu einer sicheren und transparenten KI-Entwicklung beizutragen. Darstellung in Film, Videospielen, Literatur und Musik Künstliche Wesen, die denken können, tauchen seit der Antike als Figuren in Erzählungen auf und sind ein ständiges Thema in der Science-Fiction. Seit der Klassischen Moderne wird KI in Kunst, Film und Literatur behandelt. Dabei geht es bei der künstlerischen Verarbeitung – im Gegensatz zur KI-Forschung, bei der die technische Realisierung im Vordergrund steht – vor allem um die moralischen, ethischen und religiösen Aspekte und Folgen einer nicht-menschlichen, „maschinellen Intelligenz“. In der Renaissance wurde der Begriff des Homunculus geprägt, eines künstlichen Miniaturmenschen ohne Seele. Im 18. und 19. Jahrhundert erschienen in der Literatur menschenähnliche Automaten, beispielsweise in E. T. A. Hoffmanns Der Sandmann und Jean Pauls Der Maschinenmann. Im 20. und 21. Jahrhundert greift die Science-Fiction in Film und Prosa das Thema mannigfach auf. 1920 prägte der Schriftsteller Karel Čapek den Begriff „Roboter“ in seinem Bühnenstück R.U.R.; 1926 thematisierte Fritz Lang in Metropolis Roboter, welche die Arbeit der Menschen übernehmen. Ein häufiges Motiv im Film und der Literatur begann mit Mary Shelleys Roman Frankenstein (1818), in dem eine menschliche Schöpfung zu einer Bedrohung für ihre Meister wird. Dazu gehören Werke wie Arthur C. Clarkes und Stanley Kubricks 2001: Odyssee im Weltraum (beide 1968), mit HAL 9000, dem mörderischen Computer, der das Raumschiff Discovery One steuert, sowie die Terminator-Filmreihe (ab 1984) und The Matrix (1999). Im Gegensatz dazu sind die seltenen loyalen Roboter wie Gort aus Der Tag an dem die Erde stillstand (1951) und Bishop aus Aliens (1986) in der Populärkultur weniger präsent. Mehrere Werke nutzen die künstliche Intelligenz, um uns mit der grundlegenden Frage zu konfrontieren, was uns zu Menschen macht, indem sie uns künstliche Wesen zeigen, die die Fähigkeit haben, zu fühlen und somit zu leiden. Dies geschieht in Karel Čapeks R.U.R., dem Film A.I. Artificial Intelligence von Steven Spielberg (2001) und anhand der Androidin Ava im Kinofilm Ex Machina (2015) von Alex Garland sowie in dem Roman Träumen Androiden von elektrischen Schafen? (1968) von Philip K. Dick. Dick befasst sich mit der Idee, dass unser Verständnis der menschlichen Subjektivität durch die mit künstlicher Intelligenz geschaffene Technologie verändert wird. Am 30. September 2016 veröffentlichte die US-amerikanische Pop-Rock-Band OneRepublic mit dem englischen Singer-Songwriter und Rockmusiker Peter Gabriel das Lied A.I. als digitale Single und am 7. Oktober 2016 auf dem Album Oh My My von OneRepublic. Der Song ist inspiriert von dem Film A.I. Artificial Intelligence von Steven Spielberg aus dem Jahr 2001. Die beiden großen Science-Fiction-Franchises des frühen 21. Jahrhunderts, Star Wars und Star Trek, gehen sehr unterschiedlich mit dem Thema KI um. Während bei Star Wars KI vor allem in Form von Robotern und Androiden (gleichermaßen als Statisten und Hauptfiguren) von Beginn an selbstverständlich und allgegenwärtig erscheint, nahm Star Trek im Laufe der Zeit immer wieder sehr dedizierte, wechselnde Perspektiven ein, obwohl KI auch dort meist selbstverständlich ist (z. B. Simulierte Lebewesen auf Holodecks). Beispielsweise wurde die Folge Wem gehört Data? (1989) zum Arbeitsthema mehrerer Wissenschaftler. Roboter und Androide Isaac Asimov führte die Drei Gesetze der Robotik in vielen Büchern und Geschichten ein, vor allem in der „Multivac“-Serie über einen superintelligenten Computer gleichen Namens. Asimovs Gesetze werden oft in Laiendiskussionen über Maschinenethik erwähnt; während fast alle Forscher im Bereich der künstlichen Intelligenz mit Asimovs Gesetzen durch die Populärkultur vertraut sind, halten sie die Gesetze im Allgemeinen aus vielen Gründen für nutzlos, einer davon ist ihre Zweideutigkeit. Dem Filmpublikum wurden in den unterschiedlichen Werken die Roboter als intelligente und differenzierte Maschinen mit ganz unterschiedlichen Persönlichkeiten präsentiert: Sie werden entwickelt, um sie für gute Zwecke einzusetzen, wandeln sich aber häufig zu gefährlichen Maschinen, die feindselige Pläne gegen Menschen entwickeln. Im Lauf der Filmgeschichte werden sie zunehmend zu selbstbewussten Wesen, die sich die Menschheit unterwerfen wollen. Simulierte Realität Die simulierte Realität ist zu einem häufigen Thema in der Science-Fiction geworden, wie beispielsweise in dem Film The Matrix aus dem Jahr 1999 zu sehen ist, in dem eine Welt dargestellt wird, in der künstlich intelligente Roboter die Menschheit in einer Simulation versklaven, die in der heutigen Welt angesiedelt ist. Zuvor thematisierte bereits die Star Trek TNG - Episode Das Schiff in der Flasche (1993) die Steuerung einer simulierten Realität durch eine böswillige KI, welche zuvor in der Episode Sherlock Data Holmes (1988) versehentlich erschaffen worden war. Beispiele Auswahl Filme und Literatur: Der Maschinenmensch (aka die falsche Maria) in Fritz Langs Metropolis (1927). Der Computer HAL 9000 im Kinofilm 2001 Odyssee im Weltraum (1968) von Stanley Kubrick Nomad (und andere) in der TV-Serie Raumschiff Enterprise (1966–1969) und später V'ger in Star Trek: Der Film (1979), dem ersten Kinofilm zur vorgenannten Serie. Die Elektronengehirne Colossus und Guardian im Film Colossus (1969) von Joseph Sartgent Die Androiden im Kinofilm Westworld (1973) und der US-amerikanischen Fernsehserie Westworld (2016) Die sprechenden Bomben im Film Dark Star – Finsterer Stern (1974) von John Carpenter Die meisten der seit 1977 im Star Wars Franchise (Filme, Serien, Videospiele) sichtbaren Roboter und Androide, einschließlich R2-D2 und C-3PO. Der Supercomputer Golem aus den Büchern Golem XIV und Also sprach Golem von Stanisław Lem (1981) Das Master Control Programm im Film Tron (1982) von Steven Lisberger Die Replikanten im Blade Runner Film von Ridley Scott (1982) und Blade Runner 2049 Film von Denis Villeneuve (2017) Das Auto K.I.T.T. in der US-amerikanischen Fernsehserie Knight Rider (1982–1986) Das Expertensystem des lernfähigen Computers WOPR (War Operation Plan Response) in WarGames – Kriegsspiele (1983) Die zentrale Maschineninstanz Skynet in der Terminator-Filmreihe (ab 1984) Die Roboter der fliegenden Insel Laputa im japanischen Anime-Filmklassiker Das Schloss im Himmel (1986) von Hayao Miyazaki (Studio Ghibli). Der Androide Data in der US-amerikanischen Fernsehserie Raumschiff Enterprise – Das nächste Jahrhundert (1987–1994). Hervorzuheben ist hier die Episode "Wem gehört Data?". Holografische Lebewesen und diverse Computersysteme im Star Trek Franchise (Filme, Serien, Videospiele), insbesondere der Doktor aus Star Trek: Voyager und zuletzt z. B. die KIs Control und Zora in Start Trek: Discovery Der Roboter Nummer 5 in den Filmen Nummer 5 lebt! (1986) und Nummer 5 gibt nicht auf (1988) Die Maschinen sowie sämtliche Programme (Orakel, Architekt, Agent etc.) im Film The Matrix (1999) von den Geschwistern Lana und Lilly Wachowski und den darauf basierenden Produktionen (3 weitere Filme, Serie, Spiele). Der Androide Andrew Martin im Film Der 200 Jahre Mann (2000) von Chris Columbus Die Zentralcomputer Red Queen und White Queen in den Resident-Evil Realfilmreihe (2002–2026) Der Roboter Sonny im Film I, Robot (2004) von Alex Proyas Die Tachikomas, Kampfmaschinen deren KIs in der japanischen Anime-Serie Ghost In The Shell: S.A.C. 2nd GIG (2005) ein Bewusstsein entwickeln. Der Computer Deep Thought, in der Roman- sowie Hörspielreihe des englischen Autors Douglas Adams und dem Film Per Anhalter durch die Galaxis (2005) von Garth Jennings Das geheime KI-Überwachungssystem in der US-amerikanischen Fernsehserie Person of Interest (2011–2016) Die Androiden in der schwedischen Fernsehserie Real Humans – Echte Menschen (2012–2014) Das Betriebssystem Samantha im Film Her (2013) von Spike Jonze Die Androiden in der britisch-US-amerikanischen Fernsehserie Humans (2015) Der Androide John of Us im Roman Qualityland (2017) von Marc-Uwe Kling Die Spezies der Kaylon in der Serie The Orville (2017–2023). Das KI-System A.R.E.S. in Frank Schätzings Roman Die Tyrannei des Schmetterlings (2018) Die KI TAU im gleichnamigen Film TAU von Federico D’Alessandro Die KI-Puppe M3GAN im US-amerikanischen Science-Fiction-Horrorfilm M3GAN (2023) von Gerard Johnstone Die Entität im Film Mission: Impossible – Dead Reckoning Teil Eins (2023) von Christopher McQuarrie. Raputa, eine militärische KI im japanischen Manga Deep Raputa (2024) von Kitanoda Sorakara Auswahl Videospiele: Roboter in Beneath a Steel Sky (1994) und Beyond a Steel Sky (2020) Androiden in Blade Runner (1997) Androiden in Vandell: Knight of the Tortured Souls (2002) GLaDOS in Portal und Portal 2 (2007) Androiden in Detroit: Become Human (2018) Die KI Esme in Annie and the Ai (2023) Kritik 2025 veröffentlichten 1000 britische Künstler und Gruppen das Album Is This What We Want? als Protest gegen Versuche der britischen Regierung den Urheberrechtsschutz zu Gunsten der KI-Industrie aufzuweichen. Soziale Auswirkungen Im Zuge der industriellen Revolution wurde durch die Erfindung der Dampfmaschine die Muskelkraft von der Maschine ersetzt (PS durch Watt). Durch die digitale Revolution könnte die menschliche Denkleistung durch maschinelle KI ersetzt beziehungsweise ergänzt werden. Von diversen Kennern der Materie wird angenommen, dass es zukünftig immer weniger nicht automatisierte Erwerbsarbeit gibt, weshalb auch im Hinblick auf Effizienz und Gewinnmaximierung immer weniger Arbeitskräfte benötigt würden. Der Physiker Stephen Hawking meinte, es sei klar, dass die Maschinen die Menschen zunehmend vom Arbeitsmarkt verdrängen. Microsoft-Gründer Bill Gates sieht die Entwicklung ähnlich. Er fordert eine Robotersteuer, um die sozialen Aufgaben der Zukunft bewältigen zu können. Die Informatikerin Constanze Kurz erklärte in einem Interview, der technische Wandel habe sich in der Vergangenheit meist über Generationen vollzogen, so dass genug Zeit blieb, sich für neue Aufgaben auszubilden. Heute verlaufe er innerhalb von wenigen Jahren, so dass die Menschen nicht genug Zeit hätten, sich für neue Aufgaben weiterzubilden. Der Sprecher des Chaos Computer Clubs, Frank Rieger, warnte angesichts der fortschreitenden Automatisierung unter anderem vor der Gefahr einer Schwächung von Gewerkschaften, die an Mitgliedern verlieren könnten. Er plädierte für eine „Vergesellschaftung der Automatiserungsdividende“ zugunsten eines Grundeinkommens zwecks gerechterer Wohlstandsverteilung. Jürgen Schmidhuber antwortete auf die Frage, ob KIs uns bald den Rang ablaufen werden bzw. ob wir uns Sorgen um unsere Jobs machen müssten: „Künstliche Intelligenzen werden fast alles erlernen, was Menschen können – und noch viel mehr. Ihre neuronalen Netzwerke werden aus Erfahrung klüger und wegen der sich rasch verbilligenden Hardware alle zehn Jahre hundertmal mächtiger. Unsere formelle Theorie des Spaßes erlaubt sogar, Neugierde und Kreativität zu implementieren, um künstliche Wissenschaftler und Künstler zu bauen.“ Mark Zuckerberg äußerte bei einer Rede vor Harvard-Absolventen, dass die Einführung eines bedingungslosen Grundeinkommens notwendig sei. Es könne etwas nicht mehr in Ordnung sein, wenn er als Harvard-Abbrecher innerhalb weniger Jahre Milliarden machen könne, während Millionen von Uni-Absolventen ihre Schulden nicht abbezahlen könnten. Es brauche eine Basis, auf der jeder innovativ und kreativ sein könne. Im November 2017 stellte der Deutsche-Bank-Chef John Cryan einen starken Stellenabbau in Aussicht. Cryan sagte: „Wir machen zu viel Handarbeit, was uns fehleranfällig und ineffizient macht“. Vor allem durch das maschinelle Lernen bzw. künstliche Intelligenzen könne das Unternehmen noch viel effizienter werden. Der Zukunftsforscher Lars Thomson prognostizierte im November 2017 für die nächsten zehn Jahre gewaltige Umbrüche in Technologie, Arbeit, Werten und Gesellschaft. Im Jahr 2025 könne ein Haushalts-Roboter den Frühstückstisch decken, Fenster putzen, Pflegedienste übernehmen usw. Der Markt der künstlichen Intelligenz werde in wenigen Jahren größer sein als der Automobilmarkt. In Hotels würden in zehn Jahren Roboter die Arbeiten der heutigen Zimmermädchen übernehmen. Thomson sieht die Gefahr einer Spaltung der Gesellschaft, wenn das Tempo der Veränderung die Wandlungsfähigkeit der Menschen übersteige. Die Gesellschaft müsse Leitplanken für die KIs definieren. In einem Interview im Januar 2018 meinte der CEO von Google Sundar Pichai, die aktuelle Entwicklung der künstlichen Intelligenz sei für den Werdegang der Menschheit bedeutender als es die Entdeckung des Feuers und die Entwicklung der Elektrizität waren. Durch die aktuelle Entwicklung der KI werde kein Stein auf dem anderen bleiben. Deshalb sei es wichtig, dass die Gesellschaft sich mit dem Thema auseinandersetze. Nur so könne man die Risiken eingrenzen und die Potentiale ausschöpfen. Das Institut für Arbeitsmarkt- und Berufsforschung (IAB), das zur Bundesagentur für Arbeit gehört, hat in einer Studie von 4/2018 dargelegt, welche menschliche Arbeit in Deutschland von Maschinen ersetzt werden kann. Am stärksten betroffen mit etwa 83 Prozent seien Fertigungsberufe, aber auch unternehmensbezogene Dienstleistungsberufe mit 60 Prozent, Berufe in der Unternehmensführung und -organisation mit 57 Prozent, Berufe in Land- und Forstwirtschaft und Gartenbau mit 44 Prozent usw. Insgesamt geht die Studie davon aus, dass in naher Zukunft 70 Prozent der menschlichen bezahlten Tätigkeiten von Maschinen übernommen werden könnten. Maschinen könnten z. B. übernehmen: Wareneingangskontrolle, Montageprüfung, Kommissionierung, Versicherungsanträge, Steuererklärungen usw. Die Techniken, die diese Veränderungen vorantreiben, seien: künstliche Intelligenzen, Big Data, 3D-Druck und virtuelle Realität. Auch wenn es nicht zu Entlassungen komme, müssten Mitarbeiter zumindest mit starken Veränderungen in ihrem Berufsbild und damit starkem Umlernen rechnen. Es entstünden auch neue Berufsfelder. In einem Gastbeitrag im Februar 2018 meinte der SAP-Chef Bill McDermott, um etwaige negative Auswirkungen der neuen Techniken auf die Gesellschaft zu vermeiden, brauche es eine durchdachte Planung. Behörden, Privatwirtschaft und Bildungswesen müssten zusammenarbeiten, um jungen Menschen die Fähigkeiten zu vermitteln, die diese in der digitalen Wirtschaft benötigten. Umschulungen und lebenslanges Lernen seien heute die neue Normalität. Die wirtschaftliche Entwicklung werde durch die KI befeuert. Man rechne für 2030 mit einer Wertschöpfung im Bereich von 16 Billionen US-Dollar und einem Wachstum des Bruttoinlandsprodukts um 26 Prozent. Durch die Automatisierung könnten Unternehmen zukünftig jährlich drei bis vier Billionen US-Dollar einsparen. Im August 2025 wird eine Stepstone-Analyse bekanntgemacht, die einen seit 2023 stark sinkenden Anteil an Stellenanzeigen für Berufseinsteiger abbildet. Der rasche Einsatz von Künstlicher Intelligenz verändere die Nachfrage – vor allem bei Positionen auf Juniorlevel. KI-Tools übernehmen demnach immer häufiger Berufseinsteiger-Aufgaben: Fehler in Programmcodes finden, Präsentationen vorbereiten oder Markt- und Rechtsrecherche. Das betreffe textbasierte, klar strukturierte und repetitive Jobs, beispielsweise in der Informationstechnologie, im Rechtswesen oder in der Unternehmensberatung. Damit sei langfristig nicht nur ein Umbau von Geschäftsmodellen und Unternehmensstrukturen zu erwarten, sondern es drohe auch eine Lücke in der Nachwuchsförderung, ein Problem besonders in Bereichen mit Arbeitskräftemangel wie zum Beispiel in der IT-Branche. Laut Neurowissenschaftlern der Humboldt-Universität lösten vermeidliche KI-Bilder von lächelnden Menschen bei den Betrachtern geringere Wahrnehmungs- und Gefühlsreaktionen aus. Anders sei dies bei negativen Emotionen: Auf Furcht, Trauer, Erschrecken reagierten die Gehirne der Testpersonen immer gleich, egal ob sie glaubten, KI-Gesichter oder Menschen zu sehen. Möglicherweise verlören positive Botschaften an Wert, „während die negativen mehr haften blieben“. Man könne mit KI möglicherweise leichter Angst verbreiten. Veränderte Internetsuche KI verändert die Internetsuche, indem Suchende gegenüber der klassischen Internet-Recherche komplexere Fragen stellen können und entsprechend ausformulierte Antworten erhalten. Dabei werden von den Chatbot-Antworten häufig keine Quellen angegeben (sofern nicht ausdrücklich angefragt) bzw. wenn, sind sie oft nicht verlinkt. Das veränderte Suchverhalten führt unter anderem dazu, dass Wikipedia auf direktem Weg seltener aufgerufen wird. Gleichzeitig sind jedoch die Zugriffszahlen von Chatbots auf Wikipedia zum KI-Training massiv angestiegen. Dies hat zur Folge, dass die Ressourcen der Wikipedia stärker belastet werden. Es wird angenommen, dass die Zahl der Autoren und neuer Beiträge zur Wikipedia sinken wird. Siehe auch Anwendungen künstlicher Intelligenz Deutsches Forschungszentrum für Künstliche Intelligenz Ethik der künstlichen Intelligenz Artificial General Intelligence Existenzielles Risiko durch künstliche Intelligenz Verordnung über künstliche Intelligenz seitens der EU Regulierung von künstlicher Intelligenz Künstliche Intelligenz in der Medizin KI-Ära Weblinks Literatur von und über Künstliche Intelligenz im Katalog der Deutschen Nationalbibliothek Deutsch Deutsche Zeitschrift für Künstliche Intelligenz Fachbereich Künstliche Intelligenz der Gesellschaft für Informatik (GI) Artikel zum Thema Künstliche Intelligenz bei heise.de Österreichische Gesellschaft für Artificial Intelligence (ÖGAI): oegai.at Computerwoche.de: FAQ Künstliche Intelligenz Thomas Brandstetter: Mit dem Gehirn als Vorbild zu besserer KI in Spektrum.de vom 4. November 2023 Audios Elektrotechnik-Ingenieur und Philosoph Rolf Eraßme im Gespräch: Warum man Menschen nicht nachbauen kann. Philosophische Argumente gegen die Künstliche Intelligenz. (Podcast; 40 Min.) In: Bayerischer Rundfunk. 11. Mai 2018, abgerufen am 4. Januar 2025 (Moderation: Ania Mauruschat). Zum aktuellen Stand von Künstlicher Intelligenz. (Podcast; 55 Min.) In: digitalkompakt. 25. August 2016, abgerufen am 18. November 2021. ARD – Der KI-Podcast – Wissen Videos iHuman, Tonje Hessen Schei, 2019 Vortrag von Jürgen Schmidhuber: Künstliche Intelligenz wird alles ändern, 2016 Schlaue neue Welt – Das KI-Wettrennen. Dokumentation, RBB, 2024 Englisch Peter Norvig, aima.cs.berkeley.edu: AI on the Web – Zusammenstellung weiterführender Links claire-ai.org: Confederation of Laboratories for Artificial Intelligence in Europe (CLAIRE, Föderation von KI-Forschungseinrichtungen in Europa) eurai.org: European Association for Artificial Intelligence (EurAI, früher ECCAI) Journal of Artificial Intelligence Research (JAIR) Larry Hauser: Artificial Intelligence. In: James Fieser, Bradley Dowden (Hrsg.): Internet Encyclopedia of Philosophy. John-Stewart Gordon, Sven Nyholm: Ethics of Artificial Intelligence. In: James Fieser, Bradley Dowden (Hrsg.): Internet Encyclopedia of Philosophy. Selmer Bringsjord, Naveen Sundar Govindarajulu: Artifical Intelligence. In: Edward N. Zalta (Hrsg.): Stanford Encyclopedia of Philosophy. Richmond Thomason: Logic and Artifical Intelligence. In: Edward N. Zalta (Hrsg.): Stanford Encyclopedia of Philosophy. Frederic Portoraro: Automated Reasoning. In: Edward N. Zalta (Hrsg.): Stanford Encyclopedia of Philosophy. Literatur Stuart J. Russell, Peter Norvig: Künstliche Intelligenz: Ein moderner Ansatz. Pearson Studium, Berkeley 2004, ISBN 3-8273-7089-2 (englisch: Artificial Intelligence: A Modern Approach.). Marie-Sophie Adeoso, Eva Berendsen, Leo Fischer, Deborah Schnabel: Code & Vorurteil. Über Künstliche Intelligenz, Rassismus und Antisemitismus. Verbrecher Verlag, Berlin 2024, ISBN 978-3-95732-589-1. Ingo Boersch, Jochen Heinsohn, Rolf Socher: Wissensverarbeitung – Eine Einführung in die Künstliche Intelligenz. Elsevier, 2006, ISBN 3-8274-1844-5. Stefan Buijsman: Ada und die Algorithmen. Wahre Geschichten aus der Welt der künstlichen Intelligenz. C.H.Beck, München 2021, ISBN 978-3-406-77563-5 (niederländisch: AI – Alsmaar intelligenter. Een kijkjeachter de beeldschermen. Amsterdam 2020. Übersetzt von Bärbel Jänicke). Ulrich Eberl: Smarte Maschinen: Wie Künstliche Intelligenz unser Leben verändert. Carl Hanser Verlag, München 2016, ISBN 978-3-446-44870-4. Wolfgang Ertel: Grundkurs Künstliche Intelligenz: Eine praxisorientierte Einführung. 3. Auflage. Springer Vieweg, Wiesbaden 2013, ISBN 978-3-8348-1677-1. Jörg Phil Friedrich: Degenerierte Vernunft. Künstliche Intelligenz und die Natur des Denkens. Claudius Verlag, 2023, ISBN 978-3-532-62892-8. Görz, Rollinger, Schneeberger: Handbuch der Künstlichen Intelligenz. 5. Auflage. Oldenbourg, 2013, ISBN 978-3-486-71979-6. Künstliche Intelligenz: Die Revolution der Roboter. Konradin Mediengruppe, 2019, ISSN 0006-2375 (99 Seiten). Uwe Lämmel, Jürgen Cleve: Künstliche Intelligenz. 3. Auflage. Carl Hanser Verlag, München 2008, ISBN 978-3-446-41398-6 (hs-wismar.de). Manuela Lenzen: Künstliche Intelligenz. Was sie kann und was uns erwartet. C.H.Beck, München 2018, ISBN 978-3-406-71869-4. Manuela Lenzen: Der elektronische Spiegel. Menschliches Denken und künstliche Intelligenz. C.H.Beck, München 2023, ISBN 978-3-406-79208-3. Rainer Mühlhoff: Künstliche Inteligenz und der neue Faschismus, Reclam, Stuttgart 2025 Vincent C. Müller, Martin Hähnel: Was ist, was kann, was soll KI? Ein philosophisches Gespräch, Meiner, Hamburg 2024, ISBN 978-3-7873-4672-1. Julian Nida-Rümelin, Natalie Weidenfeld: Digitaler Humanismus. Eine Ethik für das Zeitalter der Künstlichen Intelligenz, Pieper, München 32023 (12020), ISBN 978-3-492-31616-3. Nils John Nilsson: Die Suche nach Künstlicher Intelligenz – Eine Geschichte von Ideen und Erfolgen. 1. Auflage. AKA, Berlin 2014, ISBN 978-3-89838-665-4 (englisch: The quest for artificial intelligence. A history of ideas and achievements. Cambridge 2010.). Matteo Pasquinelli: Das Auge des Meisters. Eine Sozialgeschichte künstlicher Intelligenz. Unrast, Münster 2024, ISBN 978-3-89771-390-1. Roger Penrose: Schatten des Geistes. Wege zu einer neuen Physik des Bewußtseins. Heidelberg, 1995 (englisch: Shadows of the Mind.). Rolf Pfeifer, Christian Scheier, Alex Riegler: Understanding Intelligence. Bradford Books, 2001, ISBN 0-262-66125-X (englisch). David L. Poole, Alan K. Mackworth: Artificial Intelligence: Foundations of Computational Agents. 2. Auflage. Cambridge University Press, 2017, ISBN 978-1-107-19539-4 (englisch). Thomas Ramge: Mensch und Maschine. Wie Künstliche Intelligenz und Roboter unser Leben verändern. Reclam-Verlag, Stuttgart 2018, ISBN 978-3-15-019499-7. Roberto Simanowski: Sprachmaschinen: eine Philosophie der künstlichen Intelligenz. München: C.H. Beck, 2025. Anna Strasser, Wolfgang Sohst, Ralf Stapelfeldt, Katja Stepec: Künstliche Intelligenz – Die große Verheißung. Xenomoi, Berlin 2021, ISBN 978-3-942106-79-5. Mustafa Suleyman, Michael Bhaskar: The Coming Wave. Künstliche Intelligenz, Macht und das größte Dilemma des 21. Jahrhunderts. C.H.Beck, 2024, ISBN 978-3-406-81412-9. Bernd Vowinkel: Maschinen mit Bewusstsein – Wohin führt die künstliche Intelligenz? Wiley-VCH, 2006, ISBN 3-527-40630-1. Joseph Weizenbaum: Die Macht der Computer und die Ohnmacht der Vernunft. 12. Auflage. Suhrkamp, 1978, ISBN 3-518-27874-6. Emmanouil Billis, Nandor Knust, Jon-Petter Rui: Künstliche Intelligenz und der Grundsatz der Verhältnismäßigkeit. M. Engelhart, H. Kudlich, B. Vogel (Hrsg.), Digitalisierung, Globalisierung und Risikoprävention – Festschrift für Ulrich Sieber zum 70. Geburtstag, Teilband II. Duncker & Humblot, Berlin 2021, ISBN 978-3-428-15971-0, S. 693–725. == Einzelnachweise ==